{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f383e8e0-f005-423c-b936-3d6990f774bf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-10 11:46:19.455972: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.4/lib64:/usr/local/cuda-11.4/lib64:\n",
      "2022-12-10 11:46:19.456399: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.4/lib64:/usr/local/cuda-11.4/lib64:\n",
      "2022-12-10 11:46:19.456412: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/media/alexander-fyrogenis/Elements/Διδακτορικό/Olive Oil/notebooks/evoos_env/lib/python3.10/site-packages/gpflow/experimental/utils.py:42: UserWarning: You're calling gpflow.experimental.check_shapes.decorator.check_shapes which is considered *experimental*. Expect: breaking changes, poor documentation, and bugs.\n",
      "  warn(\n",
      "/media/alexander-fyrogenis/Elements/Διδακτορικό/Olive Oil/notebooks/evoos_env/lib/python3.10/site-packages/gpflow/experimental/utils.py:42: UserWarning: You're calling gpflow.experimental.check_shapes.inheritance.inherit_check_shapes which is considered *experimental*. Expect: breaking changes, poor documentation, and bugs.\n",
      "  warn(\n",
      "/media/alexander-fyrogenis/Elements/Διδακτορικό/Olive Oil/notebooks/evoos_env/lib/python3.10/site-packages/pymc/sampling/jax.py:37: UserWarning: This module is experimental.\n",
      "  warnings.warn(\"This module is experimental.\")\n",
      "/media/alexander-fyrogenis/Elements/Διδακτορικό/Olive Oil/notebooks/evoos_env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Βιβλιοθήκες\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gekko as gk\n",
    "import seaborn as sns\n",
    "import xarray as xr\n",
    "from matplotlib import pyplot as plt\n",
    "import typing\n",
    "import itertools\n",
    "import math\n",
    "import functools\n",
    "from pca import pca\n",
    "from IPython.display import display, HTML\n",
    "import prince\n",
    "import networkx\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import multiprocessing\n",
    "from imblearn.over_sampling import ADASYN, SMOTE\n",
    "import datetime\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, multilabel_confusion_matrix, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itertools import product\n",
    "import arviz as az\n",
    "import aesara\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "import aesara.tensor as at\n",
    "import scipy\n",
    "import pymc as pm, pymc\n",
    "import gpflow\n",
    "from pymc.sampling.jax import sample_numpyro_nuts\n",
    "import numpyro\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05f03a19-946d-4a07-859a-681683e6404d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Γενικές επιλογές εμφάνισης\n",
    "pd.set_option('display.max_rows',10)\n",
    "pd.set_option('display.max_columns',30)\n",
    "\n",
    "numpyro.set_platform(\"gpu\")\n",
    "\n",
    "figsize=(13,6)\n",
    "fontsize=10\n",
    "sns.set(rc={'figure.figsize':(15,10),\n",
    "           'font.size':5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc3e25ee-5947-4f7b-a31a-5295a61b0d89",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Utilities\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std_scale = lambda df: pd.DataFrame(data = StandardScaler().fit_transform(df), columns = df.columns, index=df.index)\n",
    "\n",
    "def render_df(df:pd.DataFrame):\n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML(df.to_html()))\n",
    "    return\n",
    "\n",
    "def full_display(r=None, c=None):\n",
    "    pd.set_option('display.max_rows', r)\n",
    "    pd.set_option('display.max_columns',c)\n",
    "    return\n",
    "\n",
    "def reset_display():\n",
    "    pd.set_option('display.max_rows',10)\n",
    "    pd.set_option('display.max_columns',30)\n",
    "\n",
    "def full_display_once(df:pd.DataFrame, r=None, c=None):\n",
    "    full_display(r=r, c=c)\n",
    "    render_df(df)\n",
    "    reset_display()\n",
    "\n",
    "def rowwise_value_counts(df:pd.DataFrame):\n",
    "    vcounts_df = pd.DataFrame(data = df.apply(lambda x: x.value_counts()).T.stack()).astype(int).T\n",
    "    vcounts_df.index = ['']\n",
    "    return vcounts_df\n",
    "\n",
    "invert_dict = lambda e: {v:k for k, v in e.items()}\n",
    "\n",
    "def categorical_scatter(X:pd.DataFrame, Y:typing.Optional[pd.DataFrame],cols:int=3,max_rows:int = 3,\n",
    "                             figsize:tuple[int, int] = (30, 15), xaxis_label_size: int=12,\n",
    "                             yaxis_label_size:int=12, categorical:typing.Optional[str]='hue')->typing.Optional[plt.figure]:\n",
    "    '''\n",
    "        Generate pair-wise scatter plots for a given DataFrame, with optional support for large Datasets\n",
    "        and categorical variables. Yields a figure with `max_rows x cols` scatterplots per call. When\n",
    "        `categorical=None` only generates pair-wise scatterplots for the columns of X, else generates all\n",
    "        combinations of X-column pair and Y columns. When `categorical='hue'` values of the categorical Y\n",
    "        variable will be depicted color-coded and when `categorical=size` different factors of the Y variable\n",
    "        will have different sizes instead.\n",
    "        \n",
    "        Args:\n",
    "        -----\n",
    "        \n",
    "            - X:pandas.DataFrame := The data to depict. When Y is also specified, X is assumed to be the DataFrame\n",
    "            of indicator variables\n",
    "            \n",
    "            - Y:Optional[pandas.DataFrame] := Optional Dataframe of categorical variables to depict. Ignored if \n",
    "            `category` is `None`.\n",
    "            \n",
    "            - idx_lvl:int=1 := For multilevel indexed dataframes the lowest level to squash the index on. Must be non-negative\n",
    "            \n",
    "            - cols:int=3 := Number of columns for the resulting facet grid plot. Must be non-negative. Defaults to 3\n",
    "            \n",
    "            - max_rows:int=3 := Maximum number of rows per batch the generator yields. Defaults to 3 and must be non-negative\n",
    "            \n",
    "            - figsize:tuple[int, int] := A `height x width` tuple for the generated plots. Defaults to `(30, 15)`\n",
    "            \n",
    "            - xaxis_label_size:int=12 := The size of the x-axis titles for each subplot. Must be non-negative and defaults to 12\n",
    "            \n",
    "            - yaxis_label_size:int=12 := The size of the y-axis titles for each subplot. Must be non-negative and defaults to 12\n",
    "            \n",
    "            - categorical:Optional[str] := Set the display of the categorical variable. (1) `None` ignores `Y` and only displays X\n",
    "            pair-wise scatterplots, (2) 'hue' displays the categorical variable of `Y` as color and (3) 'size' displays\n",
    "            the categorical variable with differently sized points\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        \n",
    "            - fig:matplotlib.pyplot.figure := The figure object, a FacetPlot of scatterplots\n",
    "            \n",
    "       \n",
    "       Raises:\n",
    "        ------\n",
    "        \n",
    "            - WIP\n",
    "            \n",
    "            - ValueError \n",
    "    '''\n",
    "    XY = pd.concat([Y, X], axis=1)\n",
    "    idx_lvl= XY.columns.nlevels-1\n",
    "    skip_multiindex = lambda df,i , idx_level=idx_lvl: df.columns[i][idx_level] if idx_level else df.columns[i]\n",
    "    if idx_lvl:\n",
    "        XY.columns = XY.columns.get_level_values(idx_lvl)\n",
    "    x_combs = math.comb(X.shape[1], 2)\n",
    "    MAX_ROWS = max_rows\n",
    "    \n",
    "    if categorical is not None:\n",
    "        plots = x_combs*Y.shape[1]\n",
    "    else:\n",
    "        plots = x_combs\n",
    "    ncols = cols\n",
    "    size_scaling_factor = None\n",
    "    total_rows = math.ceil(plots/ncols)\n",
    "    total_figures = math.ceil(total_rows/MAX_ROWS)\n",
    "    X_pairs = itertools.combinations(range(X.shape[1]), 2)\n",
    "    subplots = itertools.product(X_pairs,range(Y.shape[1]) ) if categorical is not None else X_pairs\n",
    "    exhaustion_sentinel = False\n",
    "    while True:\n",
    "        if exhaustion_sentinel: break\n",
    "        fig, axs = plt.subplots(nrows=MAX_ROWS, ncols=ncols, figsize=figsize)\n",
    "        ax_indices = itertools.product(range(MAX_ROWS), range(ncols), repeat=1)\n",
    "        plotslice = itertools.islice(subplots, MAX_ROWS*ncols)\n",
    "        fig_generator = itertools.zip_longest( ax_indices, plotslice, fillvalue = ((None, None), None) )\n",
    "        for (axi, axj), e in fig_generator:\n",
    "            e = tuple(flatten(e))\n",
    "            if e[0] is not None:\n",
    "                if categorical == 'size':\n",
    "                    sns.scatterplot(x=skip_multiindex(X, e[0]), y=skip_multiindex(X, e[1]), data=XY,\n",
    "                       size=skip_multiindex(Y, e[2]), ax=axs[axi, axj], legend=True)\n",
    "                elif categorical == 'hue':\n",
    "                    sns.scatterplot(x=skip_multiindex(X, e[0]), y=skip_multiindex(X, e[1]), data=XY,\n",
    "                       hue=skip_multiindex(Y, e[2]), ax=axs[axi, axj], legend=True)\n",
    "                elif categorical is None:\n",
    "                    sns.scatterplot(x=skip_multiindex(X, e[0]), y=skip_multiindex(X, e[1]), data=XY,\n",
    "                       ax=axs[axi, axj], legend=True)\n",
    "                axs[axi, axj].set_xlabel(skip_multiindex(X, e[0]))\n",
    "                axs[axi, axj].set_ylabel(skip_multiindex(X, e[1]))\n",
    "                axs[axi, axj].xaxis.label.set_size(xaxis_label_size)\n",
    "                axs[axi, axj].yaxis.label.set_size(yaxis_label_size)\n",
    "                \n",
    "            else:\n",
    "                axs[axi, axj].axis('off')\n",
    "                exhaustion_sentinel = True\n",
    "        yield fig \n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "def flatten(xs):\n",
    "    from collections.abc import Iterable\n",
    "    for x in xs:\n",
    "        if isinstance(x, Iterable) and not isinstance(x, (str, bytes)):\n",
    "            yield from flatten(x)\n",
    "        else:\n",
    "            yield x\n",
    "\n",
    "def tidy_multiindex(df:pd.DataFrame, sep:str=\".\"):\n",
    "    '''\n",
    "        Compress a hierarchically indexed dataframe to standardized tidy\n",
    "        format. A unique sepperator `sep` is used to allow reversal. All\n",
    "        levels of the index are appended together with a delimeter to allow\n",
    "        reversals.\n",
    "        \n",
    "        Args:\n",
    "        ----\n",
    "        \n",
    "            - df:pandas.DataFrame := A `pandas.DataFrame` hierarchically indexed\n",
    "            \n",
    "            - sep:str='_._' := A delimenter delineating the different levels\n",
    "            of the index. Ensure it is not present in any column name to avoid\n",
    "            a malformed index\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        \n",
    "            - ndf:pandas.DataFrame := The DataFrame with a single-level index\n",
    "    '''\n",
    "    tidy_cols = (functools.reduce(lambda e1,e2: str(e1)+sep+str(e2), col ) for col in df.columns)\n",
    "    ndf = df.copy(deep=True)\n",
    "    ndf.columns = tidy_cols\n",
    "    return ndf\n",
    "\n",
    "def reverse_tidy_multiindex(df:pd.DataFrame, sep=\".\"):\n",
    "    '''\n",
    "        Reverses the tidying to a hierachical format. Different\n",
    "        levels of the index are identified based on \"sep\"\n",
    "        \n",
    "        Args:\n",
    "        -----\n",
    "        \n",
    "            - df:pandas.DataFrame := The dataframe to process\n",
    "            \n",
    "            - sep:str='_._' := The string delimeter, sepperating\n",
    "            values for different levels of the index\n",
    "            \n",
    "        Returns:\n",
    "        -------\n",
    "        \n",
    "            - ndf:pandas.DataFrame := The dataframe with hierarchical index\n",
    "    '''\n",
    "    h_cols = (tuple(col.split(sep)) for col in df.columns)\n",
    "    ndf = df.copy(deep=True)\n",
    "    ndf.columns = pd.MultiIndex.from_tuples(h_cols)\n",
    "    return ndf\n",
    "\n",
    "def undummify(df:pd.DataFrame,cols:list[str, tuple[str]],ncol_name:typing.Union[str,tuple[str]],\n",
    "              sep:typing.Optional[str]=None,\n",
    "              rmap:typing.Optional[dict[int, typing.Union[str, tuple[str]]]]=None\n",
    "             )->pd.DataFrame:\n",
    "    '''\n",
    "        Reverses hot-encoded variables in the DataFrame. A series of hot-encoded\n",
    "        variable levels $(i_1, i2, \\dots, i_k)$ is mapped to a single new column\n",
    "        $(k)$, whose name is specified by `ncol_name`, in the new dataframe. Pre\n",
    "        vious level columns are dropped.\n",
    "        \n",
    "        Args:\n",
    "        ----\n",
    "        \n",
    "            - df:pandas.DataFrame := The DataFrame to operate upon\n",
    "            \n",
    "            - cols:list[str, tuple[str]] := A list of columns, representing the\n",
    "            levels of a categorical variable\n",
    "            \n",
    "            - sep:Optional[str] := sepperator for variable level. Currently ignored\n",
    "            \n",
    "            - ncol_name:Union[str, tuple[str]] := Name of the new categorical column\n",
    "            \n",
    "            - remap:Optional[dict[int, Union[str, tuple[str]]]] := A dictionary mapping\n",
    "            of categorical levels to values. Keys are the assumed to be levels, values\n",
    "            are assumed to be values (i.e. strings). When provided, the previous levels\n",
    "            will be replaced by the specified mappings in the new DataFrame\n",
    "            \n",
    "        Returns:\n",
    "        -------\n",
    "        \n",
    "            - ndf:pandas.DataFrame := The processed dataframe\n",
    "     '''\n",
    "    _df = coredf.loc[:, cols]\n",
    "    for i, col in enumerate(cols, 1):\n",
    "        _df.loc[:, col] = i*_df.loc[:, col]\n",
    "    ndf = df.copy(deep=True)\n",
    "    ndf.drop(cols, axis=1, inplace=True)\n",
    "    ndf[ncol_name] = _df.max(axis=1)\n",
    "    c1 = df.columns.tolist()\n",
    "    i = c1.index(cols[0])\n",
    "    swp = ndf.columns.tolist()[:i-1]+[ndf.columns.tolist()[-1]]+ndf.columns.tolist()[i:-1]\n",
    "    ndf = ndf.loc[:, swp]\n",
    "    if rmap is not None:\n",
    "        ndf = ndf.replace(rmap)\n",
    "    return ndf\n",
    "list_difference = lambda l1, l2: [e for e  in l1 if e not in set(l2)]\n",
    "\n",
    "def corrspace_graph(df:pd.DataFrame):\n",
    "    '''\n",
    "        Generate a correlation graph representation of `df` datasets.\n",
    "        Every node in the resulting graph is a variable and every \n",
    "        vertex between two nodes represents the correlation between\n",
    "        the two variables, the correlation being the verted weight\n",
    "        \n",
    "        Args:\n",
    "        ----\n",
    "        \n",
    "            - df:pandas.DataFrame := A dataset to depict\n",
    "            \n",
    "        Returns:\n",
    "            - WIP\n",
    "    '''\n",
    "    \n",
    "    return \n",
    "\n",
    "\n",
    "class DictTable(dict):\n",
    "    '''\n",
    "        Jupyter utility class that overrides the dicts' defaults\n",
    "        __repr__ rendering the input dictionary to an HTML table\n",
    "        for convenient jupyter rendering\n",
    "    '''\n",
    "    def _repr_html_(self):\n",
    "        html = [\"<table>\"]\n",
    "        for key, value in self.items():\n",
    "            html.append(\"<tr>\")\n",
    "            html.append(\"<td>{0}</td>\".format(key))\n",
    "            html.append(\"<td>{0}</td>\".format(value))\n",
    "            html.append(\"</tr>\")\n",
    "        html.append(\"</table>\")\n",
    "        return ''.join(html)\n",
    "    \n",
    "    \n",
    "def boxplots(df:pd.DataFrame, max_features:int=20, title:str=\"Boxplot\",\n",
    "             **kwargs)->typing.Generator[plt.Figure, None, None]:\n",
    "    '''\n",
    "        Wrapper around `pandas.boxplot` for datasets with a large number\n",
    "        of features. Returns a generator of boxplots of subsets of the total\n",
    "        features.\n",
    "        \n",
    "        Args:\n",
    "        -----\n",
    "        \n",
    "            - df:pandas.DataFrame := The DataFrame to plot\n",
    "            \n",
    "            - max_features:int>0 := The maximum number of features to plot\n",
    "            in each generated boxplot\n",
    "            \n",
    "            - title:str='Boxplot' := The title of the plot. A subplot index\n",
    "            of the form **(X/Y)**, tracking the current plot will be\n",
    "            appended prior to rendering\n",
    "            \n",
    "            - **kwargs:dict[str:Any] := Keyword arguments to be be forwarded\n",
    "            to pandas.DataFrame.boxplot\n",
    "            \n",
    "        Returns:\n",
    "        -------\n",
    "        \n",
    "            - Generator[plt.Figure, None, None] := A generator yielding boxplots\n",
    "            of feature subsets\n",
    "    '''\n",
    "    nplots = math.ceil(df.shape[1]/max_features)\n",
    "    for i in range(nplots):\n",
    "        if (i+1)*max_features<df.shape[1]:\n",
    "            ndf = df.iloc[:,i*max_features:(i+1)*max_features]\n",
    "        else:\n",
    "            ndf = df.iloc[:,i*max_features:df.shape[1]]\n",
    "        fig = ndf.boxplot(**kwargs)\n",
    "        fig.set_title(title + \" ({current}/{total})\".format(current=i+1, total=nplots) )\n",
    "        yield fig\n",
    "        \n",
    "def count_missing_nan(df:pd.DataFrame, axis:int=0):\n",
    "    '''\n",
    "        Return a new DataFrame with the counts of missing\n",
    "        and invalid values across specified axis.\n",
    "        \n",
    "        Args:\n",
    "        -----\n",
    "        \n",
    "            - df:pandas.DataFrame := The data\n",
    "            \n",
    "            - axis:int=0 := The axis across which missing\n",
    "            values will be enumerated. Defaults to 0 (show\n",
    "            missing values in each column)\n",
    "            \n",
    "        Returns:\n",
    "        -------\n",
    "        \n",
    "            - missing_df:pd.DataFrame := A DataFrame containing\n",
    "            counts of missing values\n",
    "    '''\n",
    "    ndf = pd.DataFrame(df.isna().sum(axis=axis)).T\n",
    "    ndf.index = ['']\n",
    "    return ndf\n",
    "\n",
    "\n",
    "class PlotPrior:\n",
    "    '''\n",
    "        WIP\n",
    "    '''\n",
    "    def __init__(self,data, columns:typing.Optional[list[str, tuple[str]]]=None,\n",
    "                 visible:bool=True, stack:bool=True, show_grid:bool=False, ncols:int=3,\n",
    "                kde:bool=True):\n",
    "        self.columns=columns\n",
    "        self.visible=visible\n",
    "        self.stack=stack\n",
    "        self.ncols=ncols\n",
    "        self.kde=kde\n",
    "        self.plots={} \n",
    "    \n",
    "    def __prep_data(self, data):\n",
    "        stacked = data.prior.stack(samples=[\"chain\", \"draw\"])\n",
    "        if self.columns is None:\n",
    "            self.columns = data.columns\n",
    "        for col in self.columns:\n",
    "            self.plots[col] = pd.DataFrame(data=stacked[col].values.T)\n",
    "    \n",
    "    def __call__(self, data, var:str):\n",
    "        df = self.plots[var]\n",
    "        k = df.shape[1]\n",
    "        n = self.ncols\n",
    "        m = (k - 1) // n + 1\n",
    "        fig, axes = plt.subplots(nrows=m, ncols=n, figsize=(n * 5, m * 3))\n",
    "        for i, (name, col) in enumerate(self.plots[var].items()):\n",
    "            r, c = i // n, i % n\n",
    "            ax = axes[r, c]\n",
    "            col.hist(ax=ax)\n",
    "            if self.kde:\n",
    "                ax2 = col.plot.kde(ax=ax, secondary_y=True, title=name)\n",
    "                ax2.set_ylim(0)\n",
    "        fig.tight_layout()\n",
    "        return fig,axs\n",
    "    \n",
    "def plot_kernel():\n",
    "    '''\n",
    "        Utility method for visualizing GP kernels. Produces a square visualization\n",
    "        of the selected kernel and all possible combinations of hyperparameters\n",
    "        \n",
    "        TODO\n",
    "        +++++\n",
    "        \n",
    "            - Extend this for combination kernels by nesting input hyperparameter\n",
    "            dicts\n",
    "            \n",
    "            - Raise combinatronic explsion error when too many hyperparameter values\n",
    "            are specified\n",
    "        \n",
    "        Args:\n",
    "        ----\n",
    "        \n",
    "            - \n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        \n",
    "            -fig:matplotlib.pyplot.Figure := The generated figure\n",
    "    '''\n",
    "    \n",
    "class MultiLayerPerceptronKernel(pymc.gp.cov.Covariance):\n",
    "    '''\n",
    "        Multi layer Perceptron Kernel a.k.a Arcsine Kernel\n",
    "        Code transplanted from `GPy.kern.src.mlp`. This kernel\n",
    "        is designed to mimic the highly nonlinear processes \n",
    "        of a Neural Network and can be thought of as the limit\n",
    "        of an A.N.N. with a single input layer as the number\n",
    "        of neurons in the hidden layer goes to infinity. Then\n",
    "        the N.N., with normal priors over the weights and biases\n",
    "        becomes equivalent to a G.P. This Kernel is given by:\n",
    "        \n",
    "        .. math::\n",
    "\n",
    "          k(x,y) = \\\\sigma^{2}\\\\frac{2}{\\\\pi }  \\\\text{asin} \\\\left\n",
    "          ( \\\\frac{ \\\\sigma_w^2 x^\\\\top y+\\\\sigma_b^2}{\\\\sqrt{\\\\sigma_w^2x^\\\\top x +\n",
    "          \\\\sigma_b^2 + 1}\\\\sqrt{\\\\sigma_w^2 y^\\\\top y + \\\\sigma_b^2 +1}} \\\\right )\n",
    "          \n",
    "        Args:\n",
    "        -----\n",
    "\n",
    "            - input_dims:int=1 := The number of input dimentions (columns) used for Covariance\n",
    "            computations. Defaults to 1 (use the first column only).\n",
    "\n",
    "            - active_dims:Optional[list[int]]=None := None or array-like specifying which input\n",
    "            dimentions will be used in computing the covariance matrix. Can be specified as a\n",
    "            a boolean vector or a vector of indices. Optional. Defaults to None, and the first\n",
    "            `input_dims` columns are selected.\n",
    "\n",
    "            - variance:Optional[float] := The output kernel variance scaling parameter, usually\n",
    "            denoted `\\eta`. Defaults to 1.0. Must be positive.\n",
    "\n",
    "            - weight_variance:Optional[Union[float, np.typing.NDArray[float]]]=1.0. The variance\n",
    "            of the weight in the A.N.N. Can be specified as either a scalar or a matrix of\n",
    "            appropriate size (same as the first input matrix). Optional.  Defaults to 1.0.\n",
    "\n",
    "            - bias_variance:Optional[Union[float, np.typing.NDArray[float]]]=1.0. The variance of\n",
    "            the biases in the A.N.N. Can be either a scalar or a matrix of appropriate size. When\n",
    "            computing covariance matrices (single input) must be a N-length vector of biases for a\n",
    "            `N \\times M` input matrix. When computing cross-covariance matrices, must be an\n",
    "            `N \\times N` matrix. Optional.  Defaults to 1.0.\n",
    "\n",
    "            - ARD:bool=False := A(utomatic)R(elevance)D(etermination) flag. Unused and raises\n",
    "            an error if switched. Optional. Defaults to False.\n",
    "        \n",
    "        \n",
    "        Returns:\n",
    "        -------\n",
    "        \n",
    "            - K:np.typing.NDArray := When called with the `.full(X)` or the `.full(X, Y)` method,\n",
    "            computes and returns the covariance or cross-covariance matrices.\n",
    "            \n",
    "            - diag(K):typing.NDArray := When called with the `.diag(X)` or `.diag(X, Y)` method\n",
    "            computes and returns the diagonal of the covariance or cross-covariance matrices\n",
    "    '''\n",
    "    four_over_tau = 2./np.pi\n",
    "    \n",
    "    def __init__(self,input_dims:int, active_dims:typing.Union[list[int], int]=None,\n",
    "                 variance:float=1.0,\n",
    "                 weight_variance:typing.Union[float, np.typing.NDArray]=1.0,\n",
    "                 bias_variance:typing.Union[float, np.typing.NDArray]=1.0, ARD:bool=False):\n",
    "        super(MultiLayerPerceptronKernel, self).__init__(input_dims, active_dims=active_dims)\n",
    "        self.variance = variance\n",
    "        self.weight_variance = weight_variance\n",
    "        self.bias_variance = bias_variance\n",
    "        if ARD:\n",
    "            raise NotImplementedError(\"Automatic Relevance Determination, not implemented\")\n",
    "        self.ARD = ARD\n",
    "\n",
    "    \n",
    "    def _comp_prod(self, X, X2=None):\n",
    "        if X2 is None:\n",
    "            return (at.math.square(X)*self.weight_variance).sum(axis=1)+self.bias_variance\n",
    "        else:\n",
    "            return (X*self.weight_variance).dot(X2.T)+self.bias_variance\n",
    "    \n",
    "    def diag(self, X):\n",
    "        \"\"\"Compute the diagonal of the covariance matrix for X.\"\"\"\n",
    "        X_prod = self._comp_prod(X)\n",
    "        return self.variance*MultiLayerPerceptronKernel.four_over_tau*at.math.arcsin(X_prod/(X_prod+1.))\n",
    "    \n",
    "    def full(self, X, X2=None):\n",
    "        if X2 is None:\n",
    "            X_denom = at.math.sqrt(self._comp_prod(X)+1.)\n",
    "            X2_denom = X_denom\n",
    "            X2 = X\n",
    "        else:\n",
    "            X_denom = at.math.sqrt(self._comp_prod(X)+1.)\n",
    "            X2_denom = at.math.sqrt(self._comp_prod(X2)+1.)\n",
    "        XTX = self._comp_prod(X,X2)/X_denom[:,None]/X2_denom[None,:]\n",
    "        return self.variance*MultiLayerPerceptronKernel.four_over_tau*at.math.arcsin(XTX)\n",
    "    \n",
    "def advi_inspect_ELBO(fit_data, show:bool=True):\n",
    "    '''\n",
    "        Utility method to investigate ADVI fit.\n",
    "        Returns log-ELBO against iterations.\n",
    "    '''\n",
    "    _h_advi_hist = fit_data.hist\n",
    "    advi_elbo = pd.DataFrame(\n",
    "        {'$log-ELBO$': -np.log(_h_advi_hist),\n",
    "         'n': np.arange(_h_advi_hist.shape[0])})\n",
    "    fig = sns.lineplot(y='$log-ELBO$', x='n', data=advi_elbo)\n",
    "    if show:\n",
    "        plt.show()\n",
    "    return fig\n",
    "\n",
    "def select_subarray(df:pd.DataFrame, targets:list[tuple[str,str,str]], indicators:list[tuple[str,str,str]],\n",
    "                   scaleX:bool=True, train_split:bool=False,\n",
    "                    mappings:typing.Optional[dict[str, typing.Union[str,int, float]]]=None,\n",
    "                    dummify:bool=False,\n",
    "                   )->tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    X = df.loc[:,indicators]\n",
    "    X = std_scale(X) if scaleX else X\n",
    "    Y = df.loc[:, targets]\n",
    "    m = Y.loc[~Y.isna().any(axis=1),:].index.intersection(X.loc[~X.isna().any(axis=1),:].index)\n",
    "    X = X.loc[m, :]\n",
    "    Y = Y.loc[m,:]\n",
    "    Y=Y.replace(mappings) if mappings is not None else Y\n",
    "    Y = pd.get_dummies(Y) if dummify else Y\n",
    "    if train_split:\n",
    "        X_train, X_test, Y_train, Y_test = sklearn.model_selection.train_test_split(X, Y,test_size=.1 ,random_state=44)\n",
    "        return X_train, X_test, Y_train, Y_test\n",
    "    else:\n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4c390cf-5b15-445b-bda5-ddeee608ad22",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tf_model(Xtrain, Xtest, Ytrain, Ytest, loss:str='categorical_crossentropy',\n",
    "             optimizer:str='adadelta',\n",
    "             layers:typing.Optional[list[tuple[int, str]]]=None,\n",
    "             metrics=['accuracy'], summary:bool=True, epochs:int=10,\n",
    "             factivation:str='sigmoid',batch:int=64, callbacks:list=[],\n",
    "            verbosity:int=1):\n",
    "    M = Xtrain.shape[1]\n",
    "    input_layer = tf.keras.Input(shape=(M,))\n",
    "    x = input_layer\n",
    "    for neurons, activation in layers:\n",
    "        x = tf.keras.layers.Dense(math.ceil(neurons), activation=activation)(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(math.ceil(Ytrain.shape[1]), activation=factivation)(x)\n",
    "    model = tf.keras.models.Model(inputs=input_layer, outputs=x)\n",
    "    model.compile(optimizer=optimizer, loss=loss, \n",
    "                metrics=metrics)\n",
    "    if summary:\n",
    "        model.summary()\n",
    "    model.fit(Xtrain, Ytrain, epochs=epochs, validation_data = (Xtest, Ytest),\n",
    "              batch_size=batch, callbacks=callbacks, verbose=verbosity)\n",
    "    return model\n",
    "# Multiple query utility\n",
    "query_multiple = lambda df, col, multiquery : functools.reduce(lambda p,n: \"{col} == '{p}' | \".format(p=p, col=col) + \"{col} == '{n}\".format(n=n, col=col), multiquery).split(\" == '\",1)[1]+\"'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fbf9133-7b8a-49e6-9577-563b61e5aeaa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tf_autoencoder(Xtrain, Xtest, Ytrain, Ytest, loss:str='categorical_crossentropy',\n",
    "             optimizer:str='adadelta',\n",
    "             layers:typing.Optional[list[tuple[int, str]]]=None,\n",
    "             metrics=['accuracy'], summary:bool=True, epochs:int=10,\n",
    "             activation:str='sigmoid',batch:int=64 ):\n",
    "    M = X.shape[1]\n",
    "    input_layer = tf.keras.Input(shape=(M,))\n",
    "    x = input_layer\n",
    "    rev_layers = copy(layers)\n",
    "    rev_layers.reverse()\n",
    "    for neurons, activation in layers:\n",
    "        x = tf.keras.layers.Dense(math.ceil(neurons), activation=activation)(x)\n",
    "    encoder = x\n",
    "    for neurons, activations in rev_layers:\n",
    "        x = tf.keras.layers.Dense(math.ceil(neurons), activation=activation)(x)\n",
    "    x = tf.keras.layers.Dense(math.ceil(Ytrain.shape[1]), activation='sigmoid')(x)\n",
    "    decoder = x\n",
    "    model = tf.keras.models.Model(inputs=input_layer, outputs=x)\n",
    "    model.compile(optimizer=optimizer, loss=loss, \n",
    "                metrics=metrics)\n",
    "    if summary:\n",
    "        model.summary()\n",
    "    model.fit(Xtrain, Ytrain, epochs=epochs, validation_data = (Xtest, Ytest),\n",
    "              batch_size=batch, verbose=1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b1fb42a-a10d-4440-aed2-e1e7828dd3fc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    with open('core_mappings.pickle', 'rb') as handle:\n",
    "        core_mappings = pickle.load(handle)\n",
    "    with open('r_core_mappings.pickle', 'rb') as handle:\n",
    "        r_core_mappings = pickle.load(handle)\n",
    "    df = pd.read_excel('evoos_processed.xlsx',header=2)\n",
    "    return core_mappings,r_core_mappings,df\n",
    "core_mappings, r_core_mappings, df = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446c8517-fae1-4675-9ca7-650efb83df58",
   "metadata": {},
   "source": [
    "#### Γκαουσιανές Διεργασίες (*Gaussian Processes*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da17a89-1c81-440f-90e2-ef82689fa6e6",
   "metadata": {},
   "source": [
    "##### Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "501a2475-7f50-437c-8fc3-5b80b12fad54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = std_scale(chem_indicators)\n",
    "# X= chem_indicators\n",
    "Y = cdf.loc[:, [(\"origin\", \"cultivation\", 'wat')]]\n",
    "m = Y.loc[~Y.isna().any(axis=1),:].index.intersection(X.loc[~X.isna().any(axis=1),:].index)\n",
    "X = X.loc[m, :]\n",
    "Y = Y.loc[m,:]\n",
    "Y=Y.replace({\"Yes\":1, \"No\":0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87ada6d-6f8d-4a06-8d30-a21bb6e9e1ae",
   "metadata": {},
   "source": [
    "he coregionalized regression model relies on the use of $\\color{firebrick}{\\textbf{multiple output kernels}}$ or $\\color{firebrick}{\\textbf{vector-valued kernels}}$ (Álvarez, Rosasco and Lawrence, 2012), of the following form:\n",
    "\n",
    "$ \\begin{align*} {\\bf B}\\otimes{\\bf K} = \\left(\\begin{array}{ccc} B_{1,1}\\times{\\bf K}({\\bf X}_{1},{\\bf X}_{1}) & \\ldots & B_{1,D}\\times{\\bf K}({\\bf X}_{1},{\\bf X}_{D})\\\\ \\vdots & \\ddots & \\vdots\\\\ B_{D,1}\\times{\\bf K}({\\bf X}_{D},{\\bf X}_{1}) & \\ldots & B_{D,D}\\times{\\bf K}({\\bf X}_{D},{\\bf X}_{D}) \\end{array}\\right) \\end{align*} $.\n",
    "\n",
    "In the expression above, ${\\bf K}$ is a kernel function, ${\\bf B}$ is a regarded as the coregionalization matrix, and ${\\bf X}_i$ represents the inputs corresponding to the $i$-th output.\n",
    "\n",
    "Notice that if $B_{i,j} = 0$ for $i \\neq j$, then all the outputs are being considered as independent of each other.\n",
    "\n",
    "To ensure that the multiple output kernel is a valid kernel, we need the $\\bf K$ and ${\\bf B}$ to be to be valid. If $\\bf K$ is already a valid kernel, we just need to ensure that ${\\bf B}$ is positive definite. The last is achieved by defining ${\\bf B} = {\\bf W}{\\bf W}^\\top + {\\boldsymbol \\kappa}{\\bf I}$, for some matrix $\\bf W$ and vector ${\\boldsymbol \\kappa}$.\n",
    "\n",
    "In GPy, a multiple output kernel is defined in the following way:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83780503-565b-4f8b-8ca3-1f5aac7c9f9a",
   "metadata": {},
   "source": [
    "Με τυπικούς πυρήνες (γραμμικός, περιοδικός, συνημιτονοειδής, ακτινωτής βάσης κ.λ.π) η επίλυση οι προβλέψεις είναι σταθερά χαμηλης πιθανότητας, κάτι που καταδεικνύει οτι το μοντέλο δεν έχει επιλύσει κάποια σχέση μεταξύ των χημικών παραμέτρων και το δεδομένων εξόδου, αλλά προβλέπει σταθερά \"αρνητικά\" για στη πλειοψηφία των περιπτώσεων οι ελιές δεν ποτίζονται. Με την εφαρμογή πυρήνα Νευρωνικού Δικτύου το πρόβλημα επιλύεται, δηλαδή έχουμε υψηλή σχετικά ακρίβεια και ποικιλία προβλήψεων, ιδιαίτερα στην μειωψηφική κατηγορία (1,0). Αυτό φαίνεται να υπονοεί ισχυρά μη-γραμμική σχέση μεταξύ χημικών παραμέτρων και ύδρευσης, κάτι για το οποίο έχουμε είδη ισχυρές ενδήξεις. Ο πυρήνας arcsin είναι:\n",
    "$$\n",
    "k(x,\\ y)\\ =\\ \\eta^2 \\frac2\\pi\\arcsin\\Bigg( \\dfrac{\\sigma_w^2x^Ty+\\sigma_b^2}{\\sqrt{\\sigma_w^2x^Tx+\\sigma_b^2+1}\\sqrt{\\sigma_w^2y^Ty+\\sigma_b^2+1}}  \\Bigg)\n",
    "$$\n",
    "\n",
    "Αυτός ο πυρήνας (*Deep Neural Networks as Gaussian Processes, J. Lee et all, 2018*) (*Large-Margin Classification in Infinite Neural Networks, Youngmin Cho et. al 2010*) σχεδιάστηκε ώστε να μιμείται τις μη-γραμμικές διεργασίες σε Νευρωνικό Δίκτυο. Βασίζεται στο Κεντρικό Οριακό Θεώρημα και αποδεικνύεται ότι Νευρωνικό Δίκτυο μοναδικό κρυφού layer γίνεται ισοδυναμεί με GP όταν τα συναπτικά βάροι και τα biases είναι κανονικά κατανεμημένα και ο αριθμός το νευρώνων απειρίζεται. Μπορεί να θεωρηθεί ως μη-γραμμικός μετασχηματισμός των δεδομένων που ακολουθείται από γραμμική παλινδρόμηση "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333e14bb-16a4-4792-a61a-feec2cbbf2f3",
   "metadata": {},
   "source": [
    "Μπορεί να απλοποιηθεί στη περιπτωσή μας ως:\n",
    "$$\n",
    "\\require{cancel}\n",
    "\\mathbf{K}(X,X^T)=\\eta^2\\frac{2}{\\pi}\\arcsin{\\Big(\\dfrac{\\sigma^2_wXX^Τ+ \\cancelto{0}{\\sigma_b^2} }{\\sigma_w^2XX^Τ+ \\cancelto{0}{\\sigma_b^2} +\\frac 1 {\\sigma^2_w} } \\Big)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea2a780-fcd3-4a43-8602-290ef60f2719",
   "metadata": {},
   "source": [
    "Ισοδυναμεί ζύγιση όλων των  μεταβλητών με τον παράγοντα $\\sigma^2_w$, κανονικοποίηση, και διαβίβαση μέσο της συνάρτησης $\\arcsin:[-1,+1]\\rightarrow [-1,+1]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfc746c-1f9d-4962-af6a-238ae7afc28f",
   "metadata": {},
   "source": [
    "Καταλήξαμε σε μοντέλο δυαδικού classification μορφής:\n",
    "$$\n",
    "\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50aca54-45a7-4a78-a66d-17b10876c67c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with pymc.Model() as binary_classification_model:\n",
    "    N,M = X_train.shape\n",
    "    σ=pymc.Normal('s', mu=2.0, sigma=0.5)\n",
    "    σ_w = pymc.MvNormal('σ_w', mu=[10.0]*M, cov=σ*np.eye(M), shape=M)\n",
    "    σ_b = pymc.Normal('σ_b',mu=10.0, sigma=2.0)\n",
    "    _η = pymc.Exponential('_η', lam=2.0)\n",
    "    ϵ = 1e-9\n",
    "    η = pymc.Deterministic('η', _η+ϵ)\n",
    "    K = MultiLayerPerceptronKernel(63, variance=η, weight_variance=σ_w, bias_variance=σ_b)\n",
    "    μ = pymc.gp.mean.Zero()\n",
    "    gp = pymc.gp.Latent(mean_func=μ, cov_func=K)\n",
    "    _f = gp.prior('_f', X=X_train.values)\n",
    "    f = pymc.Deterministic('f', at.math.sigmoid(_f))\n",
    "    y = pymc.Bernoulli('y', p = f, observed=Y_train.values[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af624e91-e487-4b56-ad58-c25c91062f42",
   "metadata": {},
   "source": [
    "##### Multiclass Unilabel Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2887c17d-b722-4122-abec-68da1ab235c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train,X_test, Y_train, Y_test = select_subarray(cdf, targets =[('origin', 'location', 'loc')], indicators=chem_indicators.columns,\n",
    "                                                train_split=True, mappings=r_core_mappings, dummify=False)\n",
    "Y_train, Y_test =  Y_train.astype(float)-1, Y_test.astype(float)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "17ce2ea9-343f-45dc-9c72-96cb0145ae9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MGP withought coregionalization\n",
    "with pymc.Model() as categorical_simple_model:\n",
    "    factors=5\n",
    "    N,M=X_train.shape\n",
    "    gps=[]\n",
    "    fs=[]\n",
    "    G = 1e7\n",
    "    η = 10.0\n",
    "    σ_b= pymc.Normal(f'σ_b', mu=0.0, sigma=0.1)\n",
    "    for factor,loc in  list(core_mappings[('origin', 'location', 'loc')].items()):\n",
    "        μ = pymc.gp.mean.Constant(0)\n",
    "        σ_c = pymc.LogNormal(f'σ_c_{loc}', mu=2.30, sigma=0.25)\n",
    "        σ_w = pymc.MvNormal(f'σ_w_{loc}', mu=3.0*np.ones(M), cov=σ_c*np.eye(M), shape=M)\n",
    "        κ =  MultiLayerPerceptronKernel(M, variance=η**2, bias_variance=σ_b**2, weight_variance=σ_w**2)\n",
    "        gp = pymc.gp.Latent(mean_func=μ, cov_func=κ)\n",
    "        gps.append(gp)\n",
    "        f = gp.prior(f'f_{loc}'.format(loc=loc),\n",
    "            X=x_tensor)\n",
    "        fs.append(f)\n",
    "    f = pymc.Deterministic('f', at.stack(*fs).T)\n",
    "    p = pymc.Deterministic('p', at.nnet.softmax(f, axis=1))\n",
    "    # y = pymc.Multinomial('y', p=p ,observed=Y_train.values, n=1)\n",
    "    y = pymc.Categorical('y', p=p, observed=y_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188e5a3e-521d-447e-8446-7b18236cedbc",
   "metadata": {},
   "source": [
    "## Intrensic Coregionalization GPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07471248-090a-4784-bf36-cef1f38f07ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = select_subarray(cdf, targets =[('origin', 'location', 'loc')], indicators=chem_indicators.columns,\n",
    "                                                train_split=False, mappings=r_core_mappings, dummify=False)\n",
    "Y = Y.astype(float)-1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a715b341-1ee6-4d44-84a6-de74ee99d5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = len(np.unique(Y.values))\n",
    "N,M = X.values.shape\n",
    "idx = np.concatenate([np.zeros(N)[:,None]]+[i*np.ones(N)[:,None] for i in range(1,factors)])\n",
    "y =Y\n",
    "x= pd.DataFrame(data= np.concatenate([idx, np.tile(X.values, (factors,1))],axis=1),columns = pd.Index([(\"\", \"\", \"GP\")]).append(X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaa9e18-c940-484e-924c-df148a9c265e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADVI = True\n",
    "MINIBATCH_ADVI_SIZE=100\n",
    "N_ITERS = 2500\n",
    "x_tensor =aesara.shared(x.values)\n",
    "y_tensor = aesara.shared(y.values[:,0])\n",
    "map_tensor_batch = {\n",
    "    y_tensor:pymc.Minibatch(y.values[:,0], MINIBATCH_ADVI_SIZE),\n",
    "    x_tensor:pymc.Minibatch(x.values, MINIBATCH_ADVI_SIZE),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b637fb1f-4a5f-4164-ab36-890d1ae1e94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/alexander-fyrogenis/Elements/Διδακτορικό/Olive Oil/notebooks/venv/lib/python3.10/site-packages/pymc/gp/cov.py:99: UserWarning: Only 63 column(s) out of 64 are being used to compute the covariance function. If this is not intended, increase 'input_dim' parameter to the number of columns to use. Ignore otherwise.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# with pymc.Model() as categorical_ICM:\n",
    "#     LOWER_BOUND_NON_NEGATIVE = 1e-4\n",
    "#     σ_n = pymc.TruncatedNormal('σ_n', mu=10.0, sigma=2, lower=LOWER_BOUND_NON_NEGATIVE, shape=x.shape[0], initval=(np.ones(x.shape[0])*1.0))\n",
    "#     k = pymc.TruncatedNormal('k', mu=10.0, sigma=2,lower=LOWER_BOUND_NON_NEGATIVE ,shape=factors)\n",
    "#     W = (-1)*pymc.TruncatedNormal('W', mu=10.0, sigma=2.0,lower=LOWER_BOUND_NON_NEGATIVE, shape=(factors,2) )\n",
    "#     σ_b = pymc.TruncatedNormal('σ_b', mu=3.0, sigma=1.0, lower=LOWER_BOUND_NON_NEGATIVE)\n",
    "#     σ_w = pymc.TruncatedNormal('σ_w',mu=3.0, sigma=0.8,lower=LOWER_BOUND_NON_NEGATIVE ,shape=x.shape[1])\n",
    "#     G = 1\n",
    "#     η = pymc.TruncatedNormal('η',mu=10, sigma=3.0, lower=LOWER_BOUND_NON_NEGATIVE)\n",
    "#     K = MultiLayerPerceptronKernel(x.shape[1],active_dims=[i for i in range(1,x.shape[1])],\n",
    "#                                   variance = G*(η+1.0), bias_variance = σ_b**2, weight_variance=σ_w**2)\n",
    "#     B = pymc.gp.cov.Coregion(X.shape[1], kappa=k, W=W, active_dims=[0])\n",
    "#     k_noise = pymc.gp.cov.WhiteNoise(σ_n)\n",
    "#     κ = (K+k_noise)*B\n",
    "#     μ = pymc.gp.mean.Constant(c=0)\n",
    "#     gp = pymc.gp.Latent(mean_func=μ, cov_func=κ)\n",
    "#     _f = gp.prior('_f', X=x_tensor)\n",
    "#     f = pymc.Deterministic('f', _f.reshape((-1, factors)))\n",
    "#     p = pymc.Deterministic('p', at.nnet.softmax(f, axis=1))\n",
    "#     y_obs = pymc.Categorical('y_obs',p=p ,observed=y_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "000a344e-b0c9-4762-9b0f-5b343e297684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # WIP Needs re-thought\n",
    "# with pymc.Model() as categorical_ICM:\n",
    "#     LOWER_BOUND_NON_NEGATIVE = 1e-4\n",
    "#     σ_n = pymc.TruncatedNormal('σ_n', mu=10.0, sigma=2, lower=LOWER_BOUND_NON_NEGATIVE, shape=M)\n",
    "#     k = pymc.TruncatedNormal('k', mu=100.0, sigma=20.0,lower=LOWER_BOUND_NON_NEGATIVE ,shape=factors)\n",
    "#     W = (-1)*pymc.TruncatedNormal('W', mu=100.0, sigma=20.0,lower=LOWER_BOUND_NON_NEGATIVE, shape=(factors,5) )\n",
    "#     weights=[]\n",
    "#     for loc in r_core_mappings[('origin','location','loc')].keys():\n",
    "#         σ_b = pymc.MvNormal(f'σ_b_{loc}', mu=3.0, sigma=1.0, lower=LOWER_BOUND_NON_NEGATIVE)\n",
    "#     σ_w = pymc.TruncatedNormal('σ_w',mu=3.0, sigma=0.8,lower=LOWER_BOUND_NON_NEGATIVE ,shape=x.shape[1]-1)\n",
    "#     G = 1\n",
    "#     η = pymc.TruncatedNormal('η',mu=3.0, sigma=1.0, lower=LOWER_BOUND_NON_NEGATIVE)\n",
    "#     K = MultiLayerPerceptronKernel(63,\n",
    "#                                   variance = G*(η**2), bias_variance = σ_b, weight_variance=σ_w)\n",
    "#     B = pymc.gp.cov.Coregion(1, kappa=k, W=W)\n",
    "#     k_noise = pymc.gp.cov.WhiteNoise(σ_n)\n",
    "#     κ = pymc.gp.cov.Kron([B,K])\n",
    "#     μ = pymc.gp.mean.Constant(c=0)\n",
    "#     gp = pymc.gp.Latent(mean_func=μ, cov_func=κ)\n",
    "#     _f = gp.prior('_f', X=x_tensor)\n",
    "#     f = pymc.Deterministic('f', _f.reshape((-1, factors)))\n",
    "#     p = pymc.Deterministic('p', at.nnet.softmax(f, axis=1))\n",
    "#     y_obs = pymc.Categorical('y_obs',p=p ,observed=y_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cd66562a-5159-466b-bab2-ff3db3e7824d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with pymc.Model() as categorical_ICM:\n",
    "#     LOWER_BOUND_NON_NEGATIVE = 1e-4\n",
    "#     σ_n = pymc.TruncatedNormal('σ_n', mu=10.0, sigma=2, lower=LOWER_BOUND_NON_NEGATIVE, shape=M)\n",
    "#     k = pymc.TruncatedNormal('k', mu=100.0, sigma=20.0,lower=LOWER_BOUND_NON_NEGATIVE ,shape=factors)\n",
    "#     W = (-1)*pymc.TruncatedNormal('W', mu=100.0, sigma=20.0,lower=LOWER_BOUND_NON_NEGATIVE, shape=(factors,2) )\n",
    "#     η = pymc.LogNormal('η', mu=.0, sigma=0.25)\n",
    "#     G = 3.0\n",
    "#     λ = pymc.MvNormal\n",
    "#     K = η**2*pymc.gp.cov.ExpQuad(63,ls=λ)\n",
    "#     B = pymc.gp.cov.Coregion(1, kappa=k, W=W)\n",
    "#     k_noise = pymc.gp.cov.WhiteNoise(σ_n)\n",
    "#     κ = pymc.gp.cov.Kron([B,K])\n",
    "#     μ = pymc.gp.mean.Constant(c=0)\n",
    "#     gp = pymc.gp.Latent(mean_func=μ, cov_func=κ)\n",
    "#     _f = gp.prior('_f', X=x_tensor)\n",
    "#     f = pymc.Deterministic('f', _f.reshape((-1, factors)))\n",
    "#     p = pymc.Deterministic('p', at.nnet.softmax(f, axis=1))\n",
    "#     y_obs = pymc.Categorical('y_obs',p=p ,observed=y_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c1fb6c-7666-487c-bcf4-03f9321a93e6",
   "metadata": {},
   "source": [
    "### General GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f925f1-71ff-44dd-86f0-4cc285b26b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "design_matrix= dict(\n",
    "    categorical = dict(\n",
    "        variables=list(),\n",
    "        kernels=list(),\n",
    "    ),\n",
    "    binary=dict( \n",
    "        variables=list(),\n",
    "        kernels=list()\n",
    "    ),\n",
    "    \n",
    "    continuous=dict(\n",
    "        variables=list(),\n",
    "        kernels=list())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2ffcf966-9733-495c-a500-faad38d82680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([('origin',    'location',           'zn'),\n",
       "            ('origin',    'location',          'loc'),\n",
       "            ('origin',    'cultivar',         'uvar'),\n",
       "            ('origin',    'cultivar',         'ucul'),\n",
       "            ('origin',    'cultivar',          'kol'),\n",
       "            ('origin',    'cultivar',          'kor'),\n",
       "            ('origin',    'cultivar',          'lad'),\n",
       "            ('origin',    'cultivar',          'adr'),\n",
       "            ('origin',    'cultivar',          'thr'),\n",
       "            ('origin',    'cultivar',          'hon'),\n",
       "            ('origin',    'cultivar',          'kal'),\n",
       "            ('origin',    'cultivar',          'man'),\n",
       "            ('origin',    'cultivar',          'chi'),\n",
       "            ('origin',    'cultivar',          'kou'),\n",
       "            ('origin',    'cultivar',          'cre'),\n",
       "            ('origin',    'cultivar',          'agr'),\n",
       "            ('origin',    'cultivar',          'dap'),\n",
       "            ('origin',    'cultivar',          'hou'),\n",
       "            ('origin',    'cultivar',          'les'),\n",
       "            ('origin',    'cultivar',          'arm'),\n",
       "            ('origin',    'cultivar',          'pat'),\n",
       "            ('origin',    'cultivar',          'amf'),\n",
       "            ('origin',    'cultivar',          'unk'),\n",
       "            ('origin', 'cultivation',        'org_b'),\n",
       "            ('origin', 'cultivation',     'altitude'),\n",
       "            ('origin', 'cultivation',          'wat'),\n",
       "            ('origin',  'production',     'mat_null'),\n",
       "            ('origin',  'production',       'mat_pa'),\n",
       "            ('origin',  'production',       'mat_pi'),\n",
       "            ('origin',  'production',        'mat_p'),\n",
       "            ('origin',  'production',        'mat_m'),\n",
       "            ('origin',  'production',         'doil'),\n",
       "            ('origin',  'production',  'colmeth_eld'),\n",
       "            ('origin',  'production', 'colmeth_eldi'),\n",
       "            ('origin',  'production',  'colmeth_mhx'),\n",
       "            ('origin',  'production', 'colmeth_temp'),\n",
       "            ('origin',  'production', 'colmeth_dixt'),\n",
       "            ('origin',  'production',  'colmeth_xte'),\n",
       "            ('origin',  'production',        'centr'),\n",
       "            ('origin',  'production',     'watadd_b'),\n",
       "            ('origin',  'production',       'kbtemp'),\n",
       "            ('origin',  'production',       'kntemp'),\n",
       "            ('origin',  'production',        'stemp')],\n",
       "           )"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdf.loc[:,['origin'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "50985f9b-9fd6-4100-87ae-a3fe2093901c",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary=[\n",
    "            ('origin', 'cultivation','wat'),\n",
    "            ('origin', 'cultivation','org_b'),\n",
    "            # ('origin',  'production',       'mat_pa'),\n",
    "            # ('origin',  'production',       'mat_pi'),\n",
    "            # ('origin',  'production',        'mat_p'),\n",
    "            # ('origin',  'production',        'mat_m'),\n",
    "            ('origin',  'production',        'centr'),\n",
    "            ('origin',  'production',     'watadd_b')\n",
    "       ]\n",
    "\n",
    "continuous = [\n",
    "            ('origin',  'production',       'kbtemp'),\n",
    "            ('origin',  'production',       'kntemp'),\n",
    "            ('origin',  'production',        'stemp'),\n",
    "            ('origin',  'production',         'doil'),\n",
    "            ]\n",
    "categorical =[\n",
    "            ('origin',    'location',          'loc'),\n",
    "            ('origin', 'cultivation',     'altitude')\n",
    "]\n",
    "categorical_hot = [\n",
    "            ('origin',    'cultivar',          'kol'),\n",
    "            ('origin',    'cultivar',          'kor'),\n",
    "            ('origin',    'cultivar',          'lad'),\n",
    "            ('origin',    'cultivar',          'adr'),\n",
    "            ('origin',    'cultivar',          'thr'),\n",
    "            ('origin',    'cultivar',          'hon'),\n",
    "            ('origin',    'cultivar',          'kal'),\n",
    "            ('origin',    'cultivar',          'man'),\n",
    "            ('origin',    'cultivar',          'chi'),\n",
    "            ('origin',    'cultivar',          'kou'),\n",
    "            ('origin',    'cultivar',          'cre'),\n",
    "            ('origin',    'cultivar',          'agr'),\n",
    "            ('origin',    'cultivar',          'dap'),\n",
    "            ('origin',    'cultivar',          'hou'),\n",
    "            ('origin',    'cultivar',          'les'),\n",
    "            ('origin',    'cultivar',          'arm'),\n",
    "            ('origin',    'cultivar',          'pat'),\n",
    "            ('origin',    'cultivar',          'amf'),\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "293527a5-a011-4960-bc0e-991ba9e0a29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=cdf.loc[:,['chemical']]\n",
    "Y=cdf.loc[:,['origin']]\n",
    "X_train,X_test,Y_train,Y_test = sklearn.model_selection.train_test_split(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "360c0959-b1d7-4609-87f3-f3773f4e80a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_valid_data = lambda target_label: Y.loc[~Y.loc[:,[target_label]].isna().any(axis=1),:].index.intersection(X.loc[~X.isna().any(axis=1),:].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "287b6eac-2dd4-4f00-839e-77e7e54c6036",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpyro.set_platform('gpu')\n",
    "with pymc.Model() as evoos_model:\n",
    "    M = X_train.shape[1]\n",
    "    # Binary\n",
    "    for binary_var in binary:\n",
    "        \n",
    "        x = X_train.loc[X_train.index.intersection(select_valid_data(binary_var)),:].values\n",
    "        _y = Y_train.loc[Y_train.index.intersection(select_valid_data(binary_var)),[binary_var] ]\n",
    "        y = _y.replace(r_core_mappings)\n",
    "        \n",
    "        m = pymc.gp.mean.Constant(c=0)\n",
    "        ls= pymc.Normal(f'l_{binary_var}', mu=3.0, sigma=1.2,shape=M)\n",
    "        k = pymc.gp.cov.ExpQuad(X_train.shape[1], ls**2)\n",
    "        \n",
    "        gp = pymc.gp.Latent(mean_func=m,cov_func=k)\n",
    "        f = gp.prior(f'f_{binary_var}', X=x)\n",
    "        p= pymc.Deterministic(f'p_{binary_var}', f.T)\n",
    "        \n",
    "        y_obs = pymc.Bernoulli(f'y_obs_{binary_var}',p=p ,observed=y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0b355b-50a3-4aa0-af44-3878650ccb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "with evoos_model:\n",
    "    idata = sample_numpyro_nuts(draws=500, tune=1000, chains=2, postprocessing_backend='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a1d743-ef5f-448d-84f8-09ec014ff2b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2864c7a3-a099-4b4c-a8bd-8804c3a7bb43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9534cfc3-6a6d-40d6-ba12-a6868b72df01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evoos_env",
   "language": "python",
   "name": "evoos_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
